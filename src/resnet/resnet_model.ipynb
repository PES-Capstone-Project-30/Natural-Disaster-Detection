{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-22 17:37:22.412855: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jacob/Tools/Python/venvs/Default/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2022-08-22 17:37:22.412887: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from keras.applications import ResNet50\n",
    "from keras.applications.resnet_v2 import preprocess_input\n",
    "from numpy import resize\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow.python.keras import Input\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.python.keras.layers import Activation, GlobalAveragePooling2D, Lambda\n",
    "from tensorflow.python.keras.layers import Conv2D\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.layers import Dropout\n",
    "from tensorflow.python.keras.layers import Flatten\n",
    "from tensorflow.python.keras.layers import MaxPooling2D\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.optimizer_v2.rmsprop import RMSprop\n",
    "from tensorflow.python.keras.utils.np_utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "image_size = (224, 224)\n",
    "image_size_ext = (224, 224, 3)\n",
    "batch_size = 5\n",
    "sample_data = \"../../sample-data\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# copilot\n",
    "def resnet_model(input_shape, num_classes):\n",
    "    # initialize the model\n",
    "    model = Sequential()\n",
    "    # first set of CONV => RELU => POOL layers\n",
    "    model.add(Conv2D(64, (3, 3), padding=\"same\", input_shape=input_shape))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=3))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    # second set of CONV => RELU => POOL layers\n",
    "    model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=3))\n",
    "    model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=3))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    # first (and only) set of FC => RELU layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    # softmax classifier\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    # return the constructed network architecture\n",
    "    return model\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def get_random_images(count: int):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    train_data_dir = \"../../data/\"\n",
    "    for sub_dir in os.listdir(train_data_dir):\n",
    "        image_list = os.listdir(\n",
    "            os.path.join(train_data_dir, sub_dir)\n",
    "        )  #list of all image names in the directory\n",
    "        image_list = list(map(lambda x: os.path.join(sub_dir, x), image_list))\n",
    "        images.extend(image_list)\n",
    "        labels.extend([sub_dir] * len(image_list))\n",
    "\n",
    "    df = pd.DataFrame({\"Images\": images, \"Labels\": labels})\n",
    "    df = df.sample(frac=1).reset_index(drop=True)  # To shuffle the data\n",
    "    df = df.head(count)  # to take the subset of data (I'm taking 100 from it)\n",
    "\n",
    "    aug = ImageDataGenerator(\n",
    "        rotation_range=30,\n",
    "        zoom_range=0.15,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.15,\n",
    "        horizontal_flip=True,\n",
    "        validation_slip=0.2,\n",
    "    )\n",
    "\n",
    "    train_generator = aug.flow_from_dataframe(\n",
    "        dataframe=df,\n",
    "        directory=train_data_dir,\n",
    "        x_col=\"Images\",\n",
    "        y_col=\"Labels\",\n",
    "        batch_size=32,\n",
    "        seed=42,\n",
    "        shuffle=True,\n",
    "        class_mode=\"categorical\",\n",
    "        target_size=image_size,\n",
    "        subset=\"training\"\n",
    "    )\n",
    "\n",
    "    validation_generator = aug.flow_from_dataframe(\n",
    "        dataframe=df,\n",
    "        directory=train_data_dir,\n",
    "        x_col=\"Images\",\n",
    "        y_col=\"Labels\",\n",
    "        batch_size=32,\n",
    "        seed=42,\n",
    "        shuffle=True,\n",
    "        class_mode=\"categorical\",\n",
    "        target_size=image_size,\n",
    "        subset=\"validation\"\n",
    "    )\n",
    "    return train_generator, validation_generator\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def read_all_images():\n",
    "    train_data_gen = ImageDataGenerator(\n",
    "        rescale=1.0 / 255,\n",
    "        shear_range=0.5,\n",
    "        zoom_range=0.7,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True\n",
    "    )\n",
    "\n",
    "    test_data_gen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "    train_data = train_data_gen.flow_from_directory(\n",
    "        \"../../sample-data/train/\",\n",
    "        target_size=(224, 224),\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    test_data = test_data_gen.flow_from_directory(\n",
    "        \"../../sample-data/test/\",\n",
    "        target_size=(224, 224),\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    return train_data, test_data\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 84 images belonging to 4 classes.\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": "(<keras.preprocessing.image.DirectoryIterator at 0x7f733c713eb0>,\n <keras.preprocessing.image.DirectoryIterator at 0x7f733c713ca0>)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_all_images()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def read_images_updated():\n",
    "    train_dataset = image_dataset_from_directory(\n",
    "        f\"{sample_data}/train\", shuffle=True, batch_size=batch_size, image_size=image_size\n",
    "    )\n",
    "\n",
    "    validation_dataset = image_dataset_from_directory(\n",
    "        f\"{sample_data}/test\", shuffle=True, batch_size=batch_size, image_size=image_size\n",
    "    )\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    pass\n",
    "\n",
    "\n",
    "def preprocess_data(X, Y):\n",
    "    x_p = preprocess_input(X)\n",
    "    y_p = to_categorical(Y, 10)\n",
    "    return x_p, y_p\n",
    "\n",
    "\n",
    "def preprocess_input_data(train_x, train_y, test_x, test_y):\n",
    "    train_x, train_y = preprocess_data(train_x, train_y)\n",
    "    test_x, test_y = preprocess_data(test_x, test_y)\n",
    "    return (train_x, train_y), (test_x, test_y)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inputs = Input(shape=image_size_ext)\n",
    "    resnet = ResNet50(weights=\"imagenet\", include_top=False, input_tensor=inputs)\n",
    "\n",
    "    for layer in resnet.layers[:170]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: resize(x, image_size)))\n",
    "    model.add(resnet)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def fit_model(model, train_x, train_y, test_x, test_y):\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=RMSprop(lr=2e-5), metrics=['accuracy']\n",
    "    )\n",
    "    checkpointer = ModelCheckpoint(\n",
    "        filepath='cifar10.h5',\n",
    "        monitor=\"val_accuracy\", verbose=1, save_best_only=True\n",
    "    )\n",
    "    model.fit(\n",
    "        train_x, train_y, batch_size=32, epochs=10, verbose=1,\n",
    "        callbacks=[checkpointer], validation_data=(test_x, test_y),\n",
    "        shuffle=True\n",
    "    )\n",
    "    model.summary()\n",
    "    model.save(\"cifar10.h5\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unexpectedly found an instance of type `<class 'tensorflow.python.keras.engine.keras_tensor.KerasTensor'>`. Expected a symbolic tensor instance.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [11]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m fit_model(\u001B[43mcreate_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m, )\n",
      "Input \u001B[0;32mIn [9]\u001B[0m, in \u001B[0;36mcreate_model\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate_model\u001B[39m():\n\u001B[1;32m      2\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m Input(shape\u001B[38;5;241m=\u001B[39mimage_size_ext)\n\u001B[0;32m----> 3\u001B[0m     resnet \u001B[38;5;241m=\u001B[39m \u001B[43mResNet50\u001B[49m\u001B[43m(\u001B[49m\u001B[43mweights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mimagenet\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minclude_top\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_tensor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m resnet\u001B[38;5;241m.\u001B[39mlayers[:\u001B[38;5;241m170\u001B[39m]:\n\u001B[1;32m      6\u001B[0m         layer\u001B[38;5;241m.\u001B[39mtrainable \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/Tools/Python/venvs/Default/lib/python3.10/site-packages/keras/applications/resnet.py:458\u001B[0m, in \u001B[0;36mResNet50\u001B[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001B[0m\n\u001B[1;32m    455\u001B[0m   x \u001B[38;5;241m=\u001B[39m stack1(x, \u001B[38;5;241m256\u001B[39m, \u001B[38;5;241m6\u001B[39m, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mconv4\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    456\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m stack1(x, \u001B[38;5;241m512\u001B[39m, \u001B[38;5;241m3\u001B[39m, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mconv5\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m--> 458\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mResNet\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstack_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mresnet50\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minclude_top\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweights\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    459\u001B[0m \u001B[43m              \u001B[49m\u001B[43minput_tensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_shape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpooling\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclasses\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Tools/Python/venvs/Default/lib/python3.10/site-packages/keras/applications/resnet.py:146\u001B[0m, in \u001B[0;36mResNet\u001B[0;34m(stack_fn, preact, use_bias, model_name, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, **kwargs)\u001B[0m\n\u001B[1;32m    144\u001B[0m   img_input \u001B[38;5;241m=\u001B[39m layers\u001B[38;5;241m.\u001B[39mInput(shape\u001B[38;5;241m=\u001B[39minput_shape)\n\u001B[1;32m    145\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 146\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[43mbackend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_keras_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_tensor\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m    147\u001B[0m     img_input \u001B[38;5;241m=\u001B[39m layers\u001B[38;5;241m.\u001B[39mInput(tensor\u001B[38;5;241m=\u001B[39minput_tensor, shape\u001B[38;5;241m=\u001B[39minput_shape)\n\u001B[1;32m    148\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/Tools/Python/venvs/Default/lib/python3.10/site-packages/keras/backend.py:1297\u001B[0m, in \u001B[0;36mis_keras_tensor\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m   1252\u001B[0m \u001B[38;5;124;03m\"\"\"Returns whether `x` is a Keras tensor.\u001B[39;00m\n\u001B[1;32m   1253\u001B[0m \n\u001B[1;32m   1254\u001B[0m \u001B[38;5;124;03mA \"Keras tensor\" is a tensor that was returned by a Keras layer,\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1291\u001B[0m \n\u001B[1;32m   1292\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1293\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x,\n\u001B[1;32m   1294\u001B[0m                   (tf\u001B[38;5;241m.\u001B[39mTensor, tf\u001B[38;5;241m.\u001B[39mVariable,\n\u001B[1;32m   1295\u001B[0m                    tf\u001B[38;5;241m.\u001B[39mSparseTensor, tf\u001B[38;5;241m.\u001B[39mRaggedTensor,\n\u001B[1;32m   1296\u001B[0m                    keras_tensor\u001B[38;5;241m.\u001B[39mKerasTensor)):\n\u001B[0;32m-> 1297\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mUnexpectedly found an instance of type `\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mtype\u001B[39m(x)) \u001B[38;5;241m+\u001B[39m\n\u001B[1;32m   1298\u001B[0m                    \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m`. Expected a symbolic tensor instance.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m   1299\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mcompat\u001B[38;5;241m.\u001B[39mv1\u001B[38;5;241m.\u001B[39mexecuting_eagerly_outside_functions():\n\u001B[1;32m   1300\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, keras_tensor\u001B[38;5;241m.\u001B[39mKerasTensor)\n",
      "\u001B[0;31mValueError\u001B[0m: Unexpectedly found an instance of type `<class 'tensorflow.python.keras.engine.keras_tensor.KerasTensor'>`. Expected a symbolic tensor instance."
     ]
    }
   ],
   "source": [
    "def training(model):\n",
    "    train_data_dir = \"\"\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1. / 255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        validation_split=0.2\n",
    "    )  # set validation split\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=\"classification\",\n",
    "        subset='training'\n",
    "    )  # set as training data\n",
    "\n",
    "    validation_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,  # same directory as training data\n",
    "        target_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=\"classification\",\n",
    "        subset='validation'\n",
    "    )  # set as validation data\n",
    "\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples // batch_size,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=validation_generator.samples // batch_size,\n",
    "        epochs=5\n",
    "    )\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}